2.1. The probability of the greedy action will be taken is 1-ε = 0.5 .

2.2. From action A4 to action A5 it definitly occurred because it was getting a positive reward but did a different action, and so, a ε (exploratory) step. And may have happened from action A1 to action A2.  

2.3. The ε=0.01 will outperform 0.1 in the long run. By about 8%, that means the algorithm will converge and will only do the 1% random action, instead of 10% random action (that it does when ε=0.1)